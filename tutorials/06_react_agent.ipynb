{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "t06_intro",
   "metadata": {},
   "source": [
    "# Tutorial 6 - The ReAct Agent (Reason + Act)\n",
    "\n",
    "## Where You Are in the Learning Journey\n",
    "\n",
    "```\n",
    " Tutorials 1-5      Tutorial 6         Tutorial 7         Tutorial 8\n",
    " RAG Fundamentals   ReAct Agent        Reflection         State\n",
    " (the retrieval     (you are here)     Self-Correction    Management\n",
    "  pipeline)                            (T7)               (T8)\n",
    "```\n",
    "\n",
    "**What this tutorial adds:** a ReAct (Reason + Act) agent that uses the RAG\n",
    "retrieval system built in Tutorials 1-5 as a *tool*.\n",
    "\n",
    "Instead of directly retrieving and answering in one fixed pipeline, the agent\n",
    "decides at each step *whether* to retrieve, *what* to search for, and *when*\n",
    "it has enough information to answer.\n",
    "\n",
    "**What you will learn in this tutorial:**\n",
    "- What an AI agent is and how it differs from a fixed pipeline\n",
    "- What the ReAct pattern is (Reason + Act)\n",
    "- What a tool call is and how the agent chooses which tool to use\n",
    "- How to trace a Thought-Action-Observation loop step by step\n",
    "- When an agent approach is better than a fixed RAG pipeline\n",
    "\n",
    "**Prerequisites:** Tutorials 1-4 (understand RAG retrieval). Python basics.\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    Q[User Question] --> T[Thought: what do I need?]\n",
    "    T --> A[Action: call a tool]\n",
    "    A --> O[Observation: tool result]\n",
    "    O --> T2{Have enough info?}\n",
    "    T2 -- No --> T\n",
    "    T2 -- Yes --> F[Final Answer]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t06_what_is_agent",
   "metadata": {},
   "source": [
    "## What Is an AI Agent?\n",
    "\n",
    "### The Difference Between a Pipeline and an Agent\n",
    "\n",
    "A **pipeline** is a fixed sequence of steps. Every question goes through the\n",
    "same steps in the same order, whether or not all steps are needed.\n",
    "\n",
    "```\n",
    "Fixed RAG Pipeline (Tutorials 1-5):\n",
    "  Question -> Embed -> Retrieve top-5 -> Generate answer\n",
    "  (always exactly these 3 steps, always top-5, always one retrieval)\n",
    "```\n",
    "\n",
    "An **agent** is a system that decides what to do next at each step. It has:\n",
    "- A set of **tools** it can call (e.g., retrieve, search, calculate)\n",
    "- A reasoning loop that chooses which tool to use and when to stop\n",
    "\n",
    "```\n",
    "ReAct Agent (this tutorial):\n",
    "  Question -> Think -> Maybe retrieve once -> Think -> Maybe retrieve again\n",
    "           -> Think -> Answer (stops when it decides it has enough)\n",
    "```\n",
    "\n",
    "### Why 'ReAct'?\n",
    "\n",
    "ReAct stands for **Reason + Act**. The agent alternates between:\n",
    "- **Reasoning**: generating a thought about what to do next\n",
    "- **Acting**: calling a tool and observing the result\n",
    "\n",
    "This was introduced in the 2022 paper 'ReAct: Synergizing Reasoning and Acting\n",
    "in Language Models' (Yao et al.).\n",
    "\n",
    "### The Three Things in Each Step\n",
    "\n",
    "Each ReAct cycle produces three things:\n",
    "\n",
    "| Step | What it is | Example |\n",
    "|------|-----------|--------|\n",
    "| Thought | The agent's reasoning about what to do | 'I need to find the leave policy.' |\n",
    "| Action  | Which tool to call and what input to give | retrieve('annual leave entitlement') |\n",
    "| Observation | What the tool returned | 'Employees get 25 days per year...' |\n",
    "\n",
    "After the observation, the agent thinks again and decides: do I have enough to\n",
    "answer the question, or do I need to call another tool?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t06_what_is_tool",
   "metadata": {},
   "source": [
    "## What Is a Tool?\n",
    "\n",
    "A **tool** is any Python callable that accepts a plain string input and returns\n",
    "a plain string output. The agent receives a dictionary of tool names to callables.\n",
    "\n",
    "In this tutorial the tool is the RAG retriever from Tutorials 1-5:\n",
    "\n",
    "```\n",
    "Tool name   : 'retrieve'\n",
    "Input       : a search query (string)\n",
    "Output      : the top-3 retrieved chunks joined as a single string\n",
    "\n",
    "Example:\n",
    "  Input  -> 'annual leave entitlement'\n",
    "  Output -> 'Chunk 1: Employees are entitled to 25 days...\n",
    "             Chunk 2: Leave accrues monthly...\n",
    "             Chunk 3: Unused leave may be carried over...'\n",
    "```\n",
    "\n",
    "By packaging retrieval as a tool, the agent can:\n",
    "- Decide when to retrieve (not every question needs retrieval)\n",
    "- Choose what to search for (reformulate the query if the first one misses)\n",
    "- Make multiple retrieval calls for complex questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t06_setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "if shutil.which(\"uv\") is None:\n",
    "    print(\"uv not found. Installing with pip...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"uv\"], check=True)\n",
    "\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root = next(\n",
    "    (path for path in [cwd, *cwd.parents] if (path / \"pyproject.toml\").exists() and (path / \"src\").exists()),\n",
    "    cwd,\n",
    ")\n",
    "os.chdir(repo_root)\n",
    "src_path = repo_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "REQUIRED_PACKAGES = [\"openai\", \"chromadb\", \"numpy\", \"pandas\", \"rank_bm25\", \"sentence_transformers\", \"dotenv\"]\n",
    "PIP_NAME_MAP = {\"rank_bm25\": \"rank-bm25\", \"sentence_transformers\": \"sentence-transformers\", \"dotenv\": \"python-dotenv\"}\n",
    "\n",
    "def find_missing(packages):\n",
    "    importlib.invalidate_caches()\n",
    "    return [pkg for pkg in packages if importlib.util.find_spec(pkg) is None]\n",
    "\n",
    "missing = find_missing(REQUIRED_PACKAGES)\n",
    "if missing:\n",
    "    print(\"Missing packages:\", missing)\n",
    "    subprocess.run([\"uv\", \"sync\"], check=True)\n",
    "\n",
    "missing_after_sync = find_missing(REQUIRED_PACKAGES)\n",
    "if missing_after_sync:\n",
    "    pip_targets = [PIP_NAME_MAP.get(pkg, pkg) for pkg in missing_after_sync]\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", *pip_targets], check=True)\n",
    "\n",
    "final_missing = find_missing(REQUIRED_PACKAGES)\n",
    "if final_missing:\n",
    "    raise ImportError(f\"Dependencies still missing: {final_missing}\")\n",
    "\n",
    "from rag_tutorials.io_utils import load_handbook_documents, load_queries\n",
    "from rag_tutorials.chunking import semantic_chunk_documents\n",
    "from rag_tutorials.pipeline import build_dense_retriever\n",
    "from rag_tutorials.qa import answer_with_context\n",
    "\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY is required\")\n",
    "\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "chat_model = os.getenv(\"OPENAI_CHAT_MODEL\", \"gpt-4.1-mini\")\n",
    "\n",
    "handbook_path = Path(\"data/handbook_manual.txt\")\n",
    "queries_path = Path(\"data/queries.jsonl\")\n",
    "if not handbook_path.exists() or not queries_path.exists():\n",
    "    raise FileNotFoundError(\"Run: uv run python scripts/generate_data.py\")\n",
    "\n",
    "documents = load_handbook_documents(handbook_path)\n",
    "queries = load_queries(queries_path)\n",
    "chunks = semantic_chunk_documents(documents)\n",
    "dense_retriever, _ = build_dense_retriever(\n",
    "    chunks=chunks,\n",
    "    collection_name=\"agent_tutorial_dense\",\n",
    "    embedding_model=embedding_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t06_build_tool",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the retrieve tool from the dense retriever (Tutorial 1-4 pipeline)\n",
    "# The tool wraps retriever output as a plain string so the agent can read it.\n",
    "\n",
    "from rag_tutorials.agent_loop import run_react_loop\n",
    "\n",
    "TOP_K = 3\n",
    "\n",
    "def retrieve_tool(query: str) -> str:\n",
    "    \"\"\"Retrieve the top-3 relevant chunks and return them as a formatted string.\"\"\"\n",
    "    results = dense_retriever(query, top_k=TOP_K)\n",
    "    if not results:\n",
    "        return \"No relevant chunks found.\"\n",
    "    parts = [f\"Chunk {i+1} [{r.chunk_id}]: {r.text}\" for i, r in enumerate(results)]\n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "tools = {\"retrieve\": retrieve_tool}\n",
    "\n",
    "print(\"Tool registered: retrieve\")\n",
    "print(\"Quick smoke test:\")\n",
    "sample_output = retrieve_tool(\"remote work VPN policy\")\n",
    "print(sample_output[:300], \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t06_trace_intro",
   "metadata": {},
   "source": [
    "## Novice Trace: Watching the Agent Think\n",
    "\n",
    "Before running a full evaluation, let us trace a single question step by step.\n",
    "Each printed block shows exactly what the agent was thinking at each step.\n",
    "\n",
    "**Question:** 'What is the maximum number of days an employee can work\n",
    "internationally before needing a Global Mobility case?'\n",
    "\n",
    "What to watch for in the trace:\n",
    "- The agent produces a **Thought** explaining why it is calling the tool\n",
    "- The **Action** is the tool name and the search query the agent chose\n",
    "- The **Observation** is what the retriever returned\n",
    "- The agent may iterate several times before it is confident enough to answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t06_trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-question agent trace\n",
    "\n",
    "question = \"What is the maximum number of days an employee can work internationally before needing a Global Mobility case?\"\n",
    "\n",
    "result = run_react_loop(\n",
    "    question=question,\n",
    "    tools=tools,\n",
    "    model=chat_model,\n",
    "    max_steps=5,\n",
    ")\n",
    "\n",
    "print(\"QUESTION:\", result.question)\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, step in enumerate(result.steps, start=1):\n",
    "    print(f\"\\n--- Step {i} ---\")\n",
    "    print(f\"Thought     : {step.thought}\")\n",
    "    print(f\"Action      : {step.action}({repr(step.action_input)})\")\n",
    "    print(f\"Observation : {step.observation[:200]}...\" if len(step.observation) > 200 else f\"Observation : {step.observation}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL ANSWER:\", result.answer)\n",
    "print(f\"\\nSteps taken : {len(result.steps)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t06_metrics_intro",
   "metadata": {},
   "source": [
    "## Evaluating Agent Answers Across Multiple Questions\n",
    "\n",
    "Now we run the agent on several questions from the shared query set and compare\n",
    "the answers to the expected source documents.\n",
    "\n",
    "We measure:\n",
    "- **Steps**: average number of Thought-Action-Observation cycles per question\n",
    "- **Tool calls**: total retrieval calls made across all questions\n",
    "- **Answer length**: a proxy for whether the agent produced a complete response\n",
    "\n",
    "Note: The same `recall_at_k` / `mrr` metrics used in Tutorials 1-5 do not apply\n",
    "directly here because the agent decides its own retrieval queries and top-k.\n",
    "Tutorial 8 (State Management) shows how to inspect individual agent runs in detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "t06_metrics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the ReAct agent on the first 5 queries and collect step statistics\n",
    "\n",
    "import time\n",
    "\n",
    "rows = []\n",
    "eval_queries = queries[:5]\n",
    "\n",
    "for q in eval_queries:\n",
    "    start = time.perf_counter()\n",
    "    agent_result = run_react_loop(\n",
    "        question=q.question,\n",
    "        tools=tools,\n",
    "        model=chat_model,\n",
    "        max_steps=5,\n",
    "    )\n",
    "    elapsed_ms = (time.perf_counter() - start) * 1000\n",
    "    rows.append({\n",
    "        \"query_id\": q.query_id,\n",
    "        \"question\": q.question[:60] + \"...\",\n",
    "        \"steps\": len(agent_result.steps),\n",
    "        \"answer_tokens\": len(agent_result.answer.split()),\n",
    "        \"latency_ms\": round(elapsed_ms, 1),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df.to_string(index=False))\n",
    "print(f\"\\nAverage steps   : {df['steps'].mean():.1f}\")\n",
    "print(f\"Average latency : {df['latency_ms'].mean():.0f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "t06_checkpoint",
   "metadata": {},
   "source": [
    "## Learning Checkpoint: ReAct Agent\n",
    "\n",
    "### What Works\n",
    "\n",
    "- The agent decides what to search for rather than using the raw user question\n",
    "  directly. This means it can reformulate a vague question into a better search\n",
    "  query.\n",
    "- The agent can make multiple retrieval calls if one is not enough, which a\n",
    "  fixed pipeline cannot do.\n",
    "- The loop terminates naturally when the agent is satisfied it has enough context.\n",
    "\n",
    "### What Does Not Work Well\n",
    "\n",
    "- The agent accepts its first answer without checking whether it is accurate.\n",
    "  If the retrieved context was misleading, the answer may be wrong and the agent\n",
    "  will not notice.\n",
    "- There is no quality gate: the agent cannot self-critique or revise.\n",
    "\n",
    "### Why Move to Tutorial 7?\n",
    "\n",
    "Tutorial 7 adds a **Critic** agent that reviews every Worker answer before it is\n",
    "returned to the user. If the answer is incomplete or inaccurate, the Critic sends\n",
    "feedback back to the Worker for revision.\n"
   ]
  }
 ]
}