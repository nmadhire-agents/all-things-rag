{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30aa400a",
   "metadata": {},
   "source": [
    "# Tutorial 3 â€” Reranking (Two-Stage Retrieval)\n",
    "\n",
    "This tutorial keeps semantic chunking and dense retrieval, then adds a second-stage reranker.\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[Query] --> B[Dense Retriever Top-10]\n",
    "    B --> C[Cross-Encoder Reranker]\n",
    "    C --> D[Reordered Top-5]\n",
    "    D --> E[LLM Answer]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e698583",
   "metadata": {},
   "source": [
    "## Learning checkpoint: what reranking solves and what remains\n",
    "\n",
    "**What works better in Tutorial 3**\n",
    "- Candidate chunks are re-ordered with stronger query awareness.\n",
    "- More relevant context should move closer to rank 1.\n",
    "- Answer quality typically improves when top context is cleaner.\n",
    "\n",
    "**Challenges you should observe**\n",
    "- Latency increases due to second-stage scoring.\n",
    "- Reranking cannot recover chunks never retrieved in first-pass.\n",
    "- Exact lexical matches can still be missed if dense retrieval under-recalls them.\n",
    "\n",
    "**Why move to Tutorial 4**\n",
    "- We now need stronger recall for exact terms and identifiers.\n",
    "- Next, we combine dense retrieval with keyword retrieval (hybrid) for coverage + precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5994d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-5) Setup, load handbook text, chunk, embed, index\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from rag_tutorials.io_utils import load_handbook_documents, load_queries\n",
    "from rag_tutorials.chunking import semantic_chunk_documents\n",
    "from rag_tutorials.pipeline import build_dense_retriever\n",
    "from rag_tutorials.reranking import LocalCrossEncoderReranker\n",
    "from rag_tutorials.qa import answer_with_context\n",
    "from rag_tutorials.evaluation import evaluate_single, summarize\n",
    "\n",
    "load_dotenv()\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY is required\")\n",
    "\n",
    "embedding_model = os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "chat_model = os.getenv(\"OPENAI_CHAT_MODEL\", \"gpt-4.1-mini\")\n",
    "\n",
    "handbook_path = Path(\"data/handbook_manual.txt\")\n",
    "queries_path = Path(\"data/queries.jsonl\")\n",
    "if not handbook_path.exists() or not queries_path.exists():\n",
    "    raise FileNotFoundError(\"Run: uv run python scripts/generate_data.py\")\n",
    "\n",
    "documents = load_handbook_documents(handbook_path)\n",
    "queries = load_queries(queries_path)\n",
    "chunks = semantic_chunk_documents(documents)\n",
    "\n",
    "dense_retriever, _ = build_dense_retriever(\n",
    "    chunks=chunks,\n",
    "    collection_name=\"tutorial3_dense_semantic\",\n",
    "    embedding_model=embedding_model,\n",
    ")\n",
    "reranker = LocalCrossEncoderReranker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19c0d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunk boundary visualization (same source text, different split strategies)\n",
    "\n",
    "from rag_tutorials.chunking import fixed_chunk_documents\n",
    "\n",
    "section_doc = next(doc for doc in documents if doc.section == \"International Work\")\n",
    "fixed_view = [c.text for c in fixed_chunk_documents([section_doc], chunk_size=120)]\n",
    "semantic_view = [c.text for c in semantic_chunk_documents([section_doc])]\n",
    "\n",
    "print(\"Section:\", section_doc.section)\n",
    "print(\"\\nFixed chunks:\")\n",
    "for idx, chunk_text in enumerate(fixed_view, start=1):\n",
    "    print(f\"[{idx}] {chunk_text}\")\n",
    "\n",
    "print(\"\\nSemantic chunks:\")\n",
    "for idx, chunk_text in enumerate(semantic_view, start=1):\n",
    "    print(f\"[{idx}] {chunk_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf296e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Retriever + reranker logic and novice score inspection\n",
    "\n",
    "def retrieve_with_rerank(question: str, first_stage_k: int = 10, final_k: int = 5):\n",
    "    first_pass = dense_retriever(question, top_k=first_stage_k)\n",
    "    reranked = reranker.rerank(question, first_pass, top_k=final_k)\n",
    "    return first_pass, reranked\n",
    "\n",
    "probe = \"What is the policy for working from another country?\"\n",
    "first_pass, reranked = retrieve_with_rerank(probe)\n",
    "\n",
    "before_df = pd.DataFrame([\n",
    "    {\"rank\": i + 1, \"chunk_id\": r.chunk_id, \"dense_score\": r.score, \"preview\": r.text[:90]}\n",
    "    for i, r in enumerate(first_pass)\n",
    "])\n",
    "after_df = pd.DataFrame([\n",
    "    {\"rank\": i + 1, \"chunk_id\": r.chunk_id, \"rerank_score\": r.score, \"preview\": r.text[:90]}\n",
    "    for i, r in enumerate(reranked)\n",
    "])\n",
    "\n",
    "print(\"Before reranking\")\n",
    "display(before_df.head(10))\n",
    "print(\"After reranking\")\n",
    "display(after_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab8615b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7-8) Prompt + end-to-end RAG query\n",
    "\n",
    "def rag_answer_reranked(question: str, top_k: int = 5):\n",
    "    _, ranked = retrieve_with_rerank(question, first_stage_k=10, final_k=top_k)\n",
    "    context = [r.text for r in ranked]\n",
    "    answer = answer_with_context(question, context, model=chat_model)\n",
    "    return answer, ranked\n",
    "\n",
    "answer, ranked = rag_answer_reranked(probe)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470dabb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9-10) Evaluation queries and debug output\n",
    "\n",
    "def retrieval_fn(question: str):\n",
    "    _, ranked = retrieve_with_rerank(question, first_stage_k=10, final_k=5)\n",
    "    return ranked\n",
    "\n",
    "rows = [\n",
    "    evaluate_single(\n",
    "        query=q,\n",
    "        retrieval_fn=retrieval_fn,\n",
    "        answer_fn=lambda question, context: answer_with_context(question, context, model=chat_model),\n",
    "        top_k=5,\n",
    "    )\n",
    "    for q in queries[:20]\n",
    "]\n",
    "\n",
    "print(\"Tutorial 3 metrics:\", summarize(rows))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
