{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "622af14c",
   "metadata": {},
   "source": [
    "# Tutorial 1 \u2014 Basic RAG (Dense Retrieval Baseline)\n",
    "\n",
    "This notebook implements a complete baseline RAG pipeline and makes embeddings + retrieval transparent for first-time learners.\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "    A[Documents] --> B[Fixed Chunking]\n",
    "    B --> C[OpenAI Embeddings]\n",
    "    C --> D[Chroma Vector Index]\n",
    "    E[User Query] --> F[Query Embedding]\n",
    "    F --> D\n",
    "    D --> G[Top-k Chunks]\n",
    "    G --> H[LLM Answer]\n",
    "```\n",
    "\n",
    "Continuity note:\n",
    "- Tutorial 2 keeps the same pipeline but changes **chunking**.\n",
    "- Tutorial 3 keeps chunking and adds **reranking**.\n",
    "- Tutorial 4 adds **hybrid retrieval** (keyword + dense)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what_is_rag",
   "metadata": {},
   "source": [
    "## What is RAG and Why Does It Exist?\n",
    "\n",
    "**Large language models (LLMs) have three fundamental limitations:**\n",
    "\n",
    "1. **Knowledge cutoff** \u2014 They are trained up to a fixed date; they know nothing about events or documents after that date.\n",
    "2. **Private data blindspot** \u2014 They have never seen your internal documents (policies, contracts, wikis, etc.).\n",
    "3. **Hallucination** \u2014 When asked something they don't reliably know, they may generate a plausible-sounding but wrong answer.\n",
    "\n",
    "**Retrieval-Augmented Generation (RAG)** solves this by giving the LLM the right information at query time:\n",
    "\n",
    "```\n",
    "User Question\n",
    "     \u2502\n",
    "     \u25bc\n",
    "[ Retriever ]  \u2190 searches your private document store\n",
    "     \u2502            returns the most relevant passages\n",
    "     \u25bc\n",
    "[ Prompt ]     \u2190 question + retrieved passages are combined\n",
    "     \u2502\n",
    "     \u25bc\n",
    "[ LLM ]        \u2190 answers ONLY from the provided context\n",
    "     \u2502\n",
    "     \u25bc\n",
    "Grounded Answer (with citations)\n",
    "```\n",
    "\n",
    "**Why this matters:**\n",
    "- The LLM does not need to memorise your documents \u2014 it reads them fresh on every query.\n",
    "- Answers are *grounded*: you can trace every claim back to a retrieved passage.\n",
    "- You can update the document store without retraining the model.\n",
    "\n",
    "**In this tutorial series we use a synthetic company handbook** (HR + international work policies)\n",
    "as the document store, so we can measure whether the right policy passage is retrieved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ed2d17",
   "metadata": {},
   "source": [
    "## Learning checkpoint: what works vs what breaks\n",
    "\n",
    "**What works in Tutorial 1**\n",
    "- Dense retrieval can find generally related handbook content.\n",
    "- End-to-end RAG flow is functional (ingest \u2192 chunk \u2192 embed \u2192 retrieve \u2192 answer).\n",
    "\n",
    "**Challenges you should observe**\n",
    "- Query intent can be too broad for nearest-neighbor retrieval.\n",
    "- Exception-heavy policy questions may return partially relevant chunks.\n",
    "- Exact policy identifiers (like forms/codes) are often weakly handled.\n",
    "\n",
    "**Why move to Tutorial 2**\n",
    "- The first bottleneck is chunk quality.\n",
    "- We next improve *how text is split* so policy context stays intact before retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "003b42c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages are available.\n",
      "Python: 3.11.13\n",
      "Working directory: /Users/avy/GitHubProjects/allagents/all-things-rag\n",
      "Repo root: /Users/avy/GitHubProjects/allagents/all-things-rag\n",
      "Using src path: /Users/avy/GitHubProjects/allagents/all-things-rag/src\n"
     ]
    }
   ],
   "source": [
    "# 1) Set Up Environment and Dependencies\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure uv is available (installs with: pip install uv)\n",
    "if shutil.which(\"uv\") is None:\n",
    "    print(\"uv not found. Installing with pip...\")\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"uv\"], check=True)\n",
    "\n",
    "# Ensure notebook runs from repo root and local src/ is importable\n",
    "cwd = Path.cwd().resolve()\n",
    "repo_root = next(\n",
    "    (path for path in [cwd, *cwd.parents] if (path / \"pyproject.toml\").exists() and (path / \"src\").exists()),\n",
    "    cwd,\n",
    ")\n",
    "os.chdir(repo_root)\n",
    "src_path = repo_root / \"src\"\n",
    "if str(src_path) not in sys.path:\n",
    "    sys.path.insert(0, str(src_path))\n",
    "\n",
    "REQUIRED_PACKAGES = [\n",
    "    \"openai\",\n",
    "    \"chromadb\",\n",
    "    \"numpy\",\n",
    "    \"pandas\",\n",
    "    \"rank_bm25\",\n",
    "    \"sentence_transformers\",\n",
    "    \"dotenv\",\n",
    "]\n",
    "\n",
    "PIP_NAME_MAP = {\n",
    "    \"rank_bm25\": \"rank-bm25\",\n",
    "    \"sentence_transformers\": \"sentence-transformers\",\n",
    "    \"dotenv\": \"python-dotenv\",\n",
    "}\n",
    "\n",
    "\n",
    "def find_missing(packages: list[str]) -> list[str]:\n",
    "    \"\"\"Return package import names not available in current kernel.\"\"\"\n",
    "    importlib.invalidate_caches()\n",
    "    return [pkg for pkg in packages if importlib.util.find_spec(pkg) is None]\n",
    "\n",
    "\n",
    "missing = find_missing(REQUIRED_PACKAGES)\n",
    "if missing:\n",
    "    print(\"Missing packages:\", missing)\n",
    "    print(\"Running: uv sync\")\n",
    "    subprocess.run([\"uv\", \"sync\"], check=True)\n",
    "\n",
    "missing_after_sync = find_missing(REQUIRED_PACKAGES)\n",
    "if missing_after_sync:\n",
    "    print(\"Still missing in active kernel after uv sync:\", missing_after_sync)\n",
    "    pip_targets = [PIP_NAME_MAP.get(pkg, pkg) for pkg in missing_after_sync]\n",
    "    print(\"Installing into current kernel with pip:\", pip_targets)\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", *pip_targets], check=True)\n",
    "\n",
    "final_missing = find_missing(REQUIRED_PACKAGES)\n",
    "if final_missing:\n",
    "    raise ImportError(f\"Dependencies still missing in current kernel: {final_missing}\")\n",
    "\n",
    "print(\"All required packages are available.\")\n",
    "print(\"Python:\", sys.version.split()[0])\n",
    "print(\"Working directory:\", Path.cwd())\n",
    "print(\"Repo root:\", repo_root)\n",
    "print(\"Using src path:\", src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c12bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(embedding_model='text-embedding-3-small', chat_model='gpt-4.1-mini', chunk_mode='fixed', top_k=5, sample_eval_size=20, handbook_path='data/handbook_manual.txt', queries_path='data/queries.jsonl')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2) Define Configuration and Paths\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    embedding_model: str = os.getenv(\"OPENAI_EMBEDDING_MODEL\", \"text-embedding-3-small\")\n",
    "    chat_model: str = os.getenv(\"OPENAI_CHAT_MODEL\", \"gpt-4.1-mini\")\n",
    "    chunk_mode: str = \"fixed\"\n",
    "    top_k: int = 5\n",
    "    sample_eval_size: int = 20\n",
    "    handbook_path: str = \"data/handbook_manual.txt\"\n",
    "    queries_path: str = \"data/queries.jsonl\"\n",
    "\n",
    "cfg = Config()\n",
    "\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY is not set. Copy .env.example to .env and set your key.\")\n",
    "\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d81fe58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source text: data/handbook_manual.txt\n",
      "Parsed handbook sections: 5\n",
      "Queries: 200\n",
      "Sample parsed document: Document(doc_id='DOC-HB-REMOTEWORK', title='Z-Tech Handbook - Remote Work', section='Remote Work', text='Z-Tech encourages remote work from home, co-working spaces, or temporary domestic locations. Employees must stay reachable during assigned timezone hours and use approved managed devices. Public Wi-Fi usage is allowed only with corporate VPN enabled. Employees are responsible for confirming local workspace privacy when joining meetings that include customer data or personnel topics. Calendar availability must reflect working blocks, breaks, and approved out-of-office windows so cross-functional teams can plan handoffs. Managers may define team-specific overlap hours when projects involve coordination across offices in different time zones. Home-office expenses are reimbursable only for pre-approved categories listed in the internal procurement guide. Employees should review ergonomic setup guidance quarterly and complete the annual safety attestation in the HR portal. Temporary domestic work from a location outside the home office state may require payroll location review if extended beyond 30 days. Use of personal devices for source-code access is prohibited unless enrolled in mobile device management and approved by security. Teams handling regulated datasets must use approved screen-sharing controls that prevent accidental exposure during demos.')\n"
     ]
    }
   ],
   "source": [
    "# 3) Load and Normalize Source Documents (shared handbook text + query set)\n",
    "\n",
    "from rag_tutorials.io_utils import load_handbook_documents, load_queries\n",
    "\n",
    "if not Path(cfg.handbook_path).exists() or not Path(cfg.queries_path).exists():\n",
    "    raise FileNotFoundError(\n",
    "        \"Shared data files are missing. Run: uv run python scripts/generate_data.py\"\n",
    "    )\n",
    "\n",
    "documents = load_handbook_documents(cfg.handbook_path)\n",
    "queries = load_queries(cfg.queries_path)\n",
    "\n",
    "print(\"Source text:\", cfg.handbook_path)\n",
    "print(\"Parsed handbook sections:\", len(documents))\n",
    "print(\"Queries:\", len(queries))\n",
    "print(\"Sample parsed document:\", documents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "why_chunk",
   "metadata": {},
   "source": [
    "### Why Do We Need to Chunk Documents?\n",
    "\n",
    "Before we can embed and index our documents, we split them into smaller pieces called **chunks**.\n",
    "There are three reasons:\n",
    "\n",
    "1. **Context window limits** \u2014 LLMs can only read a fixed number of tokens at once.\n",
    "   Feeding an entire document would overflow the limit and increase cost significantly.\n",
    "\n",
    "2. **Retrieval precision** \u2014 A chunk captures one *specific idea*.\n",
    "   If we embedded entire sections, the resulting vector would average out many ideas,\n",
    "   making it harder to match a precise query.\n",
    "\n",
    "3. **Citation quality** \u2014 Smaller chunks let us trace *exactly* which passage answered the question.\n",
    "\n",
    "**The chunk size is a hyperparameter.**\n",
    "Too small \u2192 important sentences are split across chunk boundaries.\n",
    "Too large \u2192 each chunk contains multiple unrelated ideas, diluting retrieval precision.\n",
    "Tutorial 2 addresses this directly by switching from fixed-width splitting to semantic splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ac16d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           chunk_id                    doc_id  \\\n",
      "0          DOC-HB-REMOTEWORK-FIX-00         DOC-HB-REMOTEWORK   \n",
      "1          DOC-HB-REMOTEWORK-FIX-01         DOC-HB-REMOTEWORK   \n",
      "2          DOC-HB-REMOTEWORK-FIX-02         DOC-HB-REMOTEWORK   \n",
      "3          DOC-HB-REMOTEWORK-FIX-03         DOC-HB-REMOTEWORK   \n",
      "4          DOC-HB-REMOTEWORK-FIX-04         DOC-HB-REMOTEWORK   \n",
      "5   DOC-HB-INTERNATIONALWORK-FIX-00  DOC-HB-INTERNATIONALWORK   \n",
      "6   DOC-HB-INTERNATIONALWORK-FIX-01  DOC-HB-INTERNATIONALWORK   \n",
      "7   DOC-HB-INTERNATIONALWORK-FIX-02  DOC-HB-INTERNATIONALWORK   \n",
      "8   DOC-HB-INTERNATIONALWORK-FIX-03  DOC-HB-INTERNATIONALWORK   \n",
      "9   DOC-HB-INTERNATIONALWORK-FIX-04  DOC-HB-INTERNATIONALWORK   \n",
      "10   DOC-HB-INTERNATIONALTAX-FIX-00   DOC-HB-INTERNATIONALTAX   \n",
      "11   DOC-HB-INTERNATIONALTAX-FIX-01   DOC-HB-INTERNATIONALTAX   \n",
      "12   DOC-HB-INTERNATIONALTAX-FIX-02   DOC-HB-INTERNATIONALTAX   \n",
      "13   DOC-HB-INTERNATIONALTAX-FIX-03   DOC-HB-INTERNATIONALTAX   \n",
      "14   DOC-HB-INTERNATIONALTAX-FIX-04   DOC-HB-INTERNATIONALTAX   \n",
      "15     DOC-HB-TRAVELAPPROVAL-FIX-00     DOC-HB-TRAVELAPPROVAL   \n",
      "16     DOC-HB-TRAVELAPPROVAL-FIX-01     DOC-HB-TRAVELAPPROVAL   \n",
      "17     DOC-HB-TRAVELAPPROVAL-FIX-02     DOC-HB-TRAVELAPPROVAL   \n",
      "18     DOC-HB-TRAVELAPPROVAL-FIX-03     DOC-HB-TRAVELAPPROVAL   \n",
      "19     DOC-HB-TRAVELAPPROVAL-FIX-04     DOC-HB-TRAVELAPPROVAL   \n",
      "20           DOC-HB-SECURITY-FIX-00           DOC-HB-SECURITY   \n",
      "21           DOC-HB-SECURITY-FIX-01           DOC-HB-SECURITY   \n",
      "22           DOC-HB-SECURITY-FIX-02           DOC-HB-SECURITY   \n",
      "23           DOC-HB-SECURITY-FIX-03           DOC-HB-SECURITY   \n",
      "\n",
      "               section                                               text  \n",
      "0          Remote Work  Z-Tech encourages remote work from home, co-wo...  \n",
      "1          Remote Work   are responsible for confirming local workspac...  \n",
      "2          Remote Work  ffs. Managers may define team-specific overlap...  \n",
      "3          Remote Work  view ergonomic setup guidance quarterly and co...  \n",
      "4          Remote Work  or source-code access is prohibited unless enr...  \n",
      "5   International Work  Working from another country is capped at 14 d...  \n",
      "6   International Work  xposure. Employees must submit destination cou...  \n",
      "7   International Work  ome countries require pre-travel right-to-work...  \n",
      "8   International Work  mulate toward compliance thresholds and trigge...  \n",
      "9   International Work  f approvals are denied or delayed near departu...  \n",
      "10   International Tax  Employees traveling internationally may need F...  \n",
      "11   International Tax   include expected activities, legal entity ser...  \n",
      "12   International Tax  l estimate, employees must submit an updated F...  \n",
      "13   International Tax  and work location for annual compliance audits...  \n",
      "14   International Tax  does not imply approval in another. Failure to...  \n",
      "15     Travel Approval  International travel requests must be submitte...  \n",
      "16     Travel Approval  n, estimated budget, and expected customer or ...  \n",
      "17     Travel Approval  iming exception. Hotel selections must align w...  \n",
      "18     Travel Approval  equired, budget owners must confirm cost cente...  \n",
      "19     Travel Approval   emergency contacts and destination-specific s...  \n",
      "20            Security  Employees handling customer data while traveli...  \n",
      "21            Security  pter is used. Sensitive files should remain in...  \n",
      "22            Security  ctions performed outside trusted office networ...  \n",
      "23            Security  vailable. Incident reports must include locati...  \n"
     ]
    }
   ],
   "source": [
    "# 4) Split Documents into Chunks (fixed chunking baseline)\n",
    "\n",
    "from dataclasses import asdict\n",
    "from rag_tutorials.chunking import fixed_chunk_documents\n",
    "import pandas as pd\n",
    "\n",
    "chunks = fixed_chunk_documents(documents, chunk_size=260)\n",
    "\n",
    "chunk_df = pd.DataFrame([asdict(c) for c in chunks])\n",
    "stats = {\n",
    "    \"chunk_count\": len(chunk_df),\n",
    "    \"avg_chunk_chars\": chunk_df.text.map(len).mean(),\n",
    "    \"max_chunk_chars\": chunk_df.text.map(len).max(),\n",
    "}\n",
    "#print(stats)\n",
    "print(chunk_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f14881ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section: International Work\n",
      "\n",
      "Fixed chunks:\n",
      "[1] Working from another country is capped at 14 days in a rolling 12-month period without permit support. Beyond 14 days, e\n",
      "[2] mployees must open a Global Mobility case and obtain HR, Legal, and Payroll approval. Violations can trigger immigration\n",
      "[3] , payroll, and tax exposure. Employees must submit destination country, travel dates, host entity, and work purpose when\n",
      "[4]  opening the Global Mobility case. Approval decisions depend on role type, customer access level, and whether on-site ac\n",
      "[5] tivities include contract negotiation. Some countries require pre-travel right-to-work checks even for short stays under\n",
      "[6]  the 14-day cap. International work days are counted using local calendar dates at destination, not departure timezone t\n",
      "[7] imestamps. Repeated short trips to the same country can accumulate toward compliance thresholds and trigger additional r\n",
      "[8] eview. Employees are responsible for carrying supporting approval documents while traveling in case local authorities re\n",
      "[9] quest evidence. Managers should verify project plans include fallback coverage if approvals are denied or delayed near d\n",
      "[10] eparture dates. Cross-border access to production systems may be limited by data residency rules, and engineering except\n",
      "[11] ions require sign-off.\n",
      "\n",
      "Semantic chunks:\n",
      "[1] Working from another country is capped at 14 days in a rolling 12-month period without permit support. Beyond 14 days, employees must open a Global Mobility case and obtain HR, Legal, and Payroll approval\n",
      "[2] Violations can trigger immigration, payroll, and tax exposure. Employees must submit destination country, travel dates, host entity, and work purpose when opening the Global Mobility case. Approval decisions depend on role type, customer access level, and whether on-site activities include contract negotiation. Some countries require pre-travel right-to-work checks even for short stays under the 14-day cap. International work days are counted using local calendar dates at destination, not departure timezone timestamps. Repeated short trips to the same country can accumulate toward compliance thresholds and trigger additional review. Employees are responsible for carrying supporting approval documents while traveling in case local authorities request evidence. Managers should verify project plans include fallback coverage if approvals are denied or delayed near departure dates. Cross-border access to production systems may be limited by data residency rules, and engineering exceptions require sign-off.\n"
     ]
    }
   ],
   "source": [
    "# Chunk boundary visualization (same source text, different split strategies)\n",
    "\n",
    "from rag_tutorials.chunking import semantic_chunk_documents\n",
    "\n",
    "section_doc = next(doc for doc in documents if doc.section == \"International Work\")\n",
    "fixed_view = [c.text for c in fixed_chunk_documents([section_doc], chunk_size=120)]\n",
    "semantic_view = [c.text for c in semantic_chunk_documents([section_doc])]\n",
    "\n",
    "print(\"Section:\", section_doc.section)\n",
    "print(\"\\nFixed chunks:\")\n",
    "for idx, chunk_text in enumerate(fixed_view, start=1):\n",
    "    print(f\"[{idx}] {chunk_text}\")\n",
    "\n",
    "print(\"\\nSemantic chunks:\")\n",
    "for idx, chunk_text in enumerate(semantic_view, start=1):\n",
    "    print(f\"[{idx}] {chunk_text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a9ec69",
   "metadata": {},
   "source": [
    "## Novice Lens: How Embeddings and Retrieval Actually Work\n",
    "\n",
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant U as User Query\n",
    "    participant E as Embedding Model\n",
    "    participant V as Vector Store\n",
    "    participant L as LLM\n",
    "    U->>E: \"working from another country\"\n",
    "    E->>V: query vector\n",
    "    V-->>U: top-k chunks + scores\n",
    "    U->>L: question + retrieved chunks\n",
    "    L-->>U: grounded answer\n",
    "```\n",
    "\n",
    "We will inspect:\n",
    "1. Query and chunk vectors (dimensions and first values)\n",
    "2. Cosine similarities\n",
    "3. Ranked chunk IDs returned to the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vector_basics_explainer",
   "metadata": {},
   "source": [
    "### What Is a Vector and How Does Cosine Similarity Work?\n",
    "\n",
    "An **embedding vector** is a list of floating-point numbers produced by an AI model.\n",
    "It encodes the *meaning* of a piece of text as a point in high-dimensional space\n",
    "(e.g., 1536 dimensions for `text-embedding-3-small`).\n",
    "\n",
    "Two texts with similar meaning will produce vectors that **point in roughly the same direction**.\n",
    "We measure how similar two directions are using **cosine similarity**:\n",
    "\n",
    "$$\\cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\| \\cdot \\|\\mathbf{B}\\|}$$\n",
    "\n",
    "| Score | Meaning |\n",
    "|-------|---------|\n",
    "| **1.0** | Identical direction \u2014 very similar meaning |\n",
    "| **0.5\u20130.9** | Moderate to high similarity |\n",
    "| **0.0** | Perpendicular \u2014 no similarity |\n",
    "| **< 0** | Opposite direction (rare for text) |\n",
    "\n",
    "The cell below walks through the calculation with **tiny 3-dimensional toy vectors**\n",
    "so you can see every arithmetic step before using real 1536-dim embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosine_similarity_demo",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector and cosine similarity walkthrough \u2014 toy 3-dimensional example\n",
    "# (Real OpenAI embeddings use 1536 dims; the math is identical)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Toy vectors representing meaning in 3-dimensional space\n",
    "vec_remote_work   = np.array([0.80, 0.20, 0.50])  # 'remote work policy'\n",
    "vec_leave_policy  = np.array([0.10, 0.90, 0.30])  # 'annual leave rules'\n",
    "vec_international_transfer = np.array([0.75, 0.25, 0.55])  # 'international work transfer'\n",
    "\n",
    "query_vec = np.array([0.85, 0.15, 0.45])          # query: 'working from abroad'\n",
    "\n",
    "print(\"Query vector:          \", query_vec)\n",
    "print(\"'remote work' vector:  \", vec_remote_work)\n",
    "print(\"'leave policy' vector: \", vec_leave_policy)\n",
    "print(\"'international transfer' vector:\", vec_international_transfer)\n",
    "print()\n",
    "\n",
    "# ---- Step-by-step cosine similarity: query vs 'remote work' ----\n",
    "dot_product    = np.dot(query_vec, vec_remote_work)\n",
    "norm_query     = np.linalg.norm(query_vec)\n",
    "norm_remote    = np.linalg.norm(vec_remote_work)\n",
    "cosine_score   = dot_product / (norm_query * norm_remote)\n",
    "\n",
    "print(\"=== Query vs 'remote work' ===\")\n",
    "print(f\"  dot product          : {dot_product:.4f}\")\n",
    "print(f\"  ||query||            : {norm_query:.4f}\")\n",
    "print(f\"  ||remote work||      : {norm_remote:.4f}\")\n",
    "print(f\"  cosine similarity    : {cosine_score:.4f}\")\n",
    "print()\n",
    "\n",
    "# ---- Compare all three candidates at once using the shared helper ----\n",
    "from rag_tutorials.embeddings import cosine_similarity\n",
    "\n",
    "candidates = np.stack([vec_remote_work, vec_leave_policy, vec_international_transfer])\n",
    "labels     = [\"remote work policy\", \"leave policy\", \"international transfer\"]\n",
    "scores     = cosine_similarity(query_vec, candidates)\n",
    "\n",
    "print(\"Cosine scores for query 'working from abroad':\")\n",
    "for label, score in sorted(zip(labels, scores), key=lambda x: -x[1]):\n",
    "    bar = \"\u2588\" * int(score * 20)\n",
    "    print(f\"  {label:<22} {score:.4f}  {bar}\")\n",
    "print()\n",
    "print(\"Highest score \u2192 retrieved first.  Lowest score \u2192 may not make top-k.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "what_is_vector_store",
   "metadata": {},
   "source": [
    "### What Is a Vector Store and Why Do We Need One?\n",
    "\n",
    "After embedding, we have a matrix of chunk vectors (one row per chunk).\n",
    "In principle, we could find the most relevant chunks by computing the cosine similarity\n",
    "between the query vector and every row \u2014 this is called a **brute-force search**.\n",
    "\n",
    "**Why not just do that?**\n",
    "- At 1,000 chunks it's fast. At 1,000,000 chunks it becomes unacceptably slow.\n",
    "- A **vector store** (like Chroma, used here) builds an index structure\n",
    "  that lets it skip most comparisons and return top-k results in milliseconds.\n",
    "\n",
    "**What Chroma stores for each chunk:**\n",
    "- The chunk's embedding vector (used for similarity search)\n",
    "- The chunk's raw text (returned in results)\n",
    "- Metadata (`doc_id`, `section`) for filtering and debugging\n",
    "\n",
    "At query time, Chroma embeds the question, runs approximate nearest-neighbor search,\n",
    "and returns the `top_k` chunks whose vectors are closest (by cosine distance) to the query vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41de9e52",
   "metadata": {},
   "source": [
    "### How Nearest-Neighbor Search Returns Top-k Results\n",
    "\n",
    "**The core problem:** you have a query vector and N chunk vectors in the store.\n",
    "You want the k chunks whose vectors are *closest* to the query \u2014 the **k nearest neighbors**.\n",
    "\n",
    "#### Step-by-step: what happens at query time\n",
    "\n",
    "```\n",
    "1. Embed the query           \u2192 query_vec  (1536 numbers)\n",
    "2. For each chunk vector in the store\n",
    "       score[i] = cosine_similarity(query_vec, chunk_vec[i])\n",
    "3. Sort all scores descending\n",
    "4. Return the top-k chunk texts (highest scores first)\n",
    "```\n",
    "\n",
    "The diagram below uses a tiny 4-chunk example to make every step concrete.\n",
    "\n",
    "```\n",
    "Query: 'working from abroad'\n",
    "\n",
    "chunk_A  'remote work policy'          score: 0.97  \u25c0\u2500\u2500 rank 1  \u2713 in top-3\n",
    "chunk_B  'annual leave entitlement'    score: 0.41  \u25c0\u2500\u2500 rank 4  \u2717 not in top-3\n",
    "chunk_C  'international transfer rules'score: 0.89  \u25c0\u2500\u2500 rank 2  \u2713 in top-3\n",
    "chunk_D  'parental leave procedures'   score: 0.55  \u25c0\u2500\u2500 rank 3  \u2713 in top-3\n",
    "\n",
    "top_k = 3  \u2192  returned: [chunk_A, chunk_C, chunk_D]\n",
    "```\n",
    "\n",
    "#### Exact vs Approximate Nearest-Neighbor (ANN)\n",
    "\n",
    "| Approach | How it works | When used |\n",
    "|----------|--------------|-----------|\n",
    "| **Exact (brute-force)** | Compare query against every vector | Small datasets |\n",
    "| **Approximate (ANN)** | Build an index (e.g., HNSW graph) that skips most comparisons | Large datasets |\n",
    "\n",
    "Chroma uses **HNSW** (Hierarchical Navigable Small World) by default \u2014 it builds a\n",
    "graph of vectors where nearby vectors are connected.  At query time it traverses\n",
    "the graph greedily, visiting only a small fraction of all vectors, yet finds the\n",
    "nearest neighbors with high probability.\n",
    "\n",
    "> **Key insight:** top-k is not a threshold \u2014 it is a *count*.  No matter how\n",
    "> dissimilar the best chunk is, the system always returns exactly k results.  A\n",
    "> high cosine score means \"very relevant\"; a low score means \"best we could find\n",
    "> but probably not very relevant\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e81962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nearest-neighbor top-k walkthrough \u2014 toy example\n",
    "# Shows exactly how the vector store picks which chunks to return.\n",
    "\n",
    "import numpy as np\n",
    "from rag_tutorials.embeddings import cosine_similarity\n",
    "\n",
    "# \u2500\u2500 6 toy chunk vectors (3-dim for readability; real ones are 1536-dim) \u2500\u2500\n",
    "chunk_vectors = np.array([\n",
    "    [0.80, 0.20, 0.50],   # chunk 0: 'remote work policy'\n",
    "    [0.10, 0.90, 0.30],   # chunk 1: 'annual leave entitlement'\n",
    "    [0.75, 0.25, 0.55],   # chunk 2: 'international transfer rules'\n",
    "    [0.15, 0.70, 0.40],   # chunk 3: 'parental leave procedures'\n",
    "    [0.60, 0.35, 0.65],   # chunk 4: 'home-office equipment policy'\n",
    "    [0.05, 0.95, 0.20],   # chunk 5: 'sick leave documentation'\n",
    "])\n",
    "chunk_labels = [\n",
    "    \"remote work policy\",\n",
    "    \"annual leave entitlement\",\n",
    "    \"international transfer rules\",\n",
    "    \"parental leave procedures\",\n",
    "    \"home-office equipment policy\",\n",
    "    \"sick leave documentation\",\n",
    "]\n",
    "\n",
    "query_vec = np.array([0.85, 0.15, 0.45])   # query: 'working from abroad'\n",
    "TOP_K = 3\n",
    "\n",
    "# \u2500\u2500 Step 1: compute cosine similarity to every chunk \u2500\u2500\n",
    "scores = cosine_similarity(query_vec, chunk_vectors)\n",
    "\n",
    "# \u2500\u2500 Step 2: rank by descending score \u2500\u2500\n",
    "ranked_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "print(f\"Query: 'working from abroad'\")\n",
    "print(f\"\\nAll {len(chunk_labels)} chunks ranked by cosine similarity:\")\n",
    "print(f\"{'Rank':<5} {'Score':>6}  {'Chunk label'}\")\n",
    "print(\"-\" * 50)\n",
    "for rank, idx in enumerate(ranked_indices, 1):\n",
    "    selected = \" \u25c0 top-k\" if rank <= TOP_K else \"\"\n",
    "    bar = \"\u2588\" * int(scores[idx] * 20)\n",
    "    print(f\"  {rank:<4} {scores[idx]:.4f}  {chunk_labels[idx]:<30} {bar}{selected}\")\n",
    "\n",
    "# \u2500\u2500 Step 3: return top-k \u2500\u2500\n",
    "top_k_indices = ranked_indices[:TOP_K]\n",
    "print(f\"\\n\u2192 top_k={TOP_K} chunks returned to the LLM:\")\n",
    "for i, idx in enumerate(top_k_indices, 1):\n",
    "    print(f\"  {i}. [{scores[idx]:.4f}] {chunk_labels[idx]}\")\n",
    "\n",
    "print(\"\\n\u2192 chunks NOT retrieved (score too low for top-k):\")\n",
    "for idx in ranked_indices[TOP_K:]:\n",
    "    print(f\"  [ ] [{scores[idx]:.4f}] {chunk_labels[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e644a40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding matrix shape: (24, 1536)\n",
      "Example vector (first 10 dims): [ 0.0294  0.0544  0.0442  0.0226  0.002  -0.0399  0.0043  0.0554  0.0151\n",
      "  0.0031]\n",
      "Toy chunk 1 cosine score: 0.4026\n",
      "Toy chunk 2 cosine score: 0.2809\n",
      "Toy chunk 3 cosine score: 0.3770\n"
     ]
    }
   ],
   "source": [
    "# 5) Create Embeddings and Build Vector Index\n",
    "# Each chunk text is converted into a high-dimensional vector (1536 dims for text-embedding-3-small).\n",
    "# These vectors are stored in Chroma so we can search by cosine similarity at query time.\n",
    "\n",
    "from rag_tutorials.pipeline import build_dense_retriever\n",
    "from rag_tutorials.embeddings import embed_texts, cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "dense_retriever, doc_vectors = build_dense_retriever(\n",
    "    chunks=chunks,\n",
    "    collection_name=\"tutorial1_basic_dense\",\n",
    "    embedding_model=cfg.embedding_model,\n",
    ")\n",
    "\n",
    "# doc_vectors shape: (num_chunks, embedding_dim)\n",
    "# Each row is one chunk's vector; columns are learned numeric features.\n",
    "print(\"Embedding matrix shape (chunks \u00d7 dims):\", doc_vectors.shape)\n",
    "print(\"First chunk vector \u2014 first 10 of\", doc_vectors.shape[1], \"dimensions:\")\n",
    "print(\" \", np.round(doc_vectors[0][:10], 4))\n",
    "print(\"  (every dimension encodes a subtle aspect of meaning)\")\n",
    "print()\n",
    "\n",
    "# --- Real-embedding cosine similarity trace using 3 actual chunks ---\n",
    "# We embed the same query and three chunks with the real model so you can\n",
    "# see that the pattern from the toy demo above holds for real vectors too.\n",
    "sample_texts = [chunks[i].text for i in range(3)]\n",
    "sample_vectors = embed_texts(sample_texts, model=cfg.embedding_model)\n",
    "sample_query = \"What is the policy for working from another country?\"\n",
    "sample_query_vector = embed_texts([sample_query], model=cfg.embedding_model)[0]\n",
    "\n",
    "scores = cosine_similarity(sample_query_vector, sample_vectors)\n",
    "print(\"Real cosine similarity scores (query vs first 3 chunks):\")\n",
    "for idx, (score, text) in enumerate(zip(scores, sample_texts), start=1):\n",
    "    bar = \"\u2588\" * int(score * 20)\n",
    "    print(f\"  Chunk {idx} score={score:.4f}  {bar}\")\n",
    "    print(f\"    preview: {text[:80]}...\")\n",
    "print()\n",
    "print(\"The full index contains\", doc_vectors.shape[0], \"chunks; Chroma runs the same\")\n",
    "print(\"cosine comparison for ALL of them and returns the top-k highest scores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "67817acd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>score</th>\n",
       "      <th>source</th>\n",
       "      <th>preview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DOC-HB-INTERNATIONALWORK-FIX-00</td>\n",
       "      <td>0.168518</td>\n",
       "      <td>dense</td>\n",
       "      <td>Working from another country is capped at 14 d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>DOC-HB-INTERNATIONALWORK-FIX-02</td>\n",
       "      <td>0.084514</td>\n",
       "      <td>dense</td>\n",
       "      <td>ome countries require pre-travel right-to-work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DOC-HB-INTERNATIONALTAX-FIX-00</td>\n",
       "      <td>-0.031337</td>\n",
       "      <td>dense</td>\n",
       "      <td>Employees traveling internationally may need F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>DOC-HB-INTERNATIONALWORK-FIX-01</td>\n",
       "      <td>-0.095470</td>\n",
       "      <td>dense</td>\n",
       "      <td>xposure. Employees must submit destination cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>DOC-HB-REMOTEWORK-FIX-03</td>\n",
       "      <td>-0.113855</td>\n",
       "      <td>dense</td>\n",
       "      <td>view ergonomic setup guidance quarterly and co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                         chunk_id     score source  \\\n",
       "0     1  DOC-HB-INTERNATIONALWORK-FIX-00  0.168518  dense   \n",
       "1     2  DOC-HB-INTERNATIONALWORK-FIX-02  0.084514  dense   \n",
       "2     3   DOC-HB-INTERNATIONALTAX-FIX-00 -0.031337  dense   \n",
       "3     4  DOC-HB-INTERNATIONALWORK-FIX-01 -0.095470  dense   \n",
       "4     5         DOC-HB-REMOTEWORK-FIX-03 -0.113855  dense   \n",
       "\n",
       "                                             preview  \n",
       "0  Working from another country is capped at 14 d...  \n",
       "1  ome countries require pre-travel right-to-work...  \n",
       "2  Employees traveling internationally may need F...  \n",
       "3  xposure. Employees must submit destination cou...  \n",
       "4  view ergonomic setup guidance quarterly and co...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6) Implement Retriever Logic\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_dense(question: str, top_k: int = 5):\n",
    "    return dense_retriever(question, top_k=top_k)\n",
    "\n",
    "probe_query = \"What is the policy for working from another country?\"\n",
    "probe_results = retrieve_dense(probe_query, top_k=cfg.top_k)\n",
    "\n",
    "pd.DataFrame([\n",
    "    {\n",
    "        \"rank\": idx + 1,\n",
    "        \"chunk_id\": row.chunk_id,\n",
    "        \"score\": row.score,\n",
    "        \"source\": row.source,\n",
    "        \"preview\": row.text,\n",
    "    }\n",
    "    for idx, row in enumerate(probe_results)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "334d86b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probe question: What is the policy for working from another country?\n",
      "Retrieved context: ['Working from another country is capped at 14 days in a rolling 12-month period without permit support. Beyond 14 days, employees must open a Global Mobility case and obtain HR, Legal, and Payroll approval. Violations can trigger immigration, payroll, and tax e', 'ome countries require pre-travel right-to-work checks even for short stays under the 14-day cap. International work days are counted using local calendar dates at destination, not departure timezone timestamps. Repeated short trips to the same country can accu', 'Employees traveling internationally may need Form A-12 before departure when cross-border work exceeds 7 business days. The tax team uses Form A-12 to assess treaty relief, withholding obligations, and permanent establishment risk. Form A-12 submissions should', 'xposure. Employees must submit destination country, travel dates, host entity, and work purpose when opening the Global Mobility case. Approval decisions depend on role type, customer access level, and whether on-site activities include contract negotiation. S', 'view ergonomic setup guidance quarterly and complete the annual safety attestation in the HR portal. Temporary domestic work from a location outside the home office state may require payroll location review if extended beyond 30 days. Use of personal devices f']\n",
      "Employees can work from another country up to 14 days in a rolling 12-month period without permit support. Beyond 14 days, they must open a Global Mobility case and obtain HR, Legal, and Payroll approval. Additional requirements include submitting details like destination country, travel dates, host entity, and work purpose for approval. Violations can lead to immigration, payroll, and tax exposure [Chunk 1, Chunk 4].\n"
     ]
    }
   ],
   "source": [
    "# 7) Implement Prompt Template and LLM Call\n",
    "# RAG injects the retrieved chunks directly into the LLM prompt.\n",
    "# We print the full prompt below so you can see exactly what the model receives.\n",
    "\n",
    "from rag_tutorials.qa import answer_with_context, build_context\n",
    "\n",
    "def rag_answer(question: str, top_k: int = 5):\n",
    "    retrieved = retrieve_dense(question, top_k=top_k)\n",
    "    context = [r.text for r in retrieved]\n",
    "    answer = answer_with_context(question, context, model=cfg.chat_model)\n",
    "    return answer, retrieved\n",
    "\n",
    "# --- Show the actual prompt that is sent to the LLM ---\n",
    "context_chunks = [r.text for r in probe_results]\n",
    "context_block = build_context(context_chunks)\n",
    "full_prompt = (\n",
    "    \"You are a policy assistant. Answer only from the provided context. \"\n",
    "    \"If the answer is not present, say you do not have enough context.\\n\\n\"\n",
    "    f\"Question: {probe_query}\\n\\n\"\n",
    "    f\"Context:\\n{context_block}\\n\\n\"\n",
    "    \"Provide a concise answer and include a short citation like [Chunk 1].\"\n",
    ")\n",
    "print(\"=\" * 60)\n",
    "print(\"FULL PROMPT SENT TO LLM:\")\n",
    "print(\"=\" * 60)\n",
    "print(full_prompt)\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(\"The LLM only sees the text above \u2014 it cannot look outside this prompt.\")\n",
    "print(\"This is what 'grounding' means: the answer must come from these chunks.\")\n",
    "print()\n",
    "\n",
    "print(\"Probe question:\", probe_query)\n",
    "answer, retrieved = rag_answer(probe_query)\n",
    "print(\"LLM answer:\")\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metrics_explainer",
   "metadata": {},
   "source": [
    "### How to Read the Evaluation Metrics\n",
    "\n",
    "Before running the evaluation loop, here is what each metric measures:\n",
    "\n",
    "| Metric | What it measures | Range | Higher = better? |\n",
    "|--------|-----------------|-------|------------------|\n",
    "| **Recall@k** | Did the *correct* document appear anywhere in the top-k retrieved chunks? | 0 \u2013 1 | \u2713 |\n",
    "| **MRR** (Mean Reciprocal Rank) | How high was the first correct hit? 1/rank, averaged over queries | 0 \u2013 1 | \u2713 |\n",
    "| **Groundedness** | What fraction of the answer's words also appear in the retrieved context? | 0 \u2013 1 | \u2713 |\n",
    "| **Latency (ms)** | Wall-clock time for one full query (retrieve + generate) | milliseconds | \u2717 (lower) |\n",
    "\n",
    "**Worked example:**\n",
    "- Query: *\"Can I work remotely from abroad?\"*\n",
    "- Correct source: `handbook-international-work`\n",
    "- Retrieved top-5: `[handbook-leave, handbook-international-work, ...]`\n",
    "  - Recall@5 = **1.0** (correct doc is in top 5)\n",
    "  - MRR = **0.5** (correct doc is at rank 2, so 1/2 = 0.5)\n",
    "\n",
    "**Typical starting-point ranges for this small dataset:**\n",
    "- Recall@5 \u2265 0.6 is functional; \u2265 0.8 is good.\n",
    "- MRR \u2265 0.5 means the answer usually lands in the top 2.\n",
    "- Groundedness \u2265 0.5 means roughly half the answer words came from context.\n",
    "\n",
    "Watch how these numbers change across Tutorial 1 \u2192 2 \u2192 3 \u2192 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49376064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tutorial 1 metrics: {'recall_at_k': 1.0, 'mrr': 0.975, 'latency_ms': 1826.7711563268676, 'groundedness': 0.7853514886656859}\n",
      "Retrieved context: ['Z-Tech encourages remote work from home, co-working spaces, or temporary domestic locations. Employees must stay reachable during assigned timezone hours and use approved managed devices. Public Wi-Fi usage is allowed only with corporate VPN enabled. Employees', 'view ergonomic setup guidance quarterly and complete the annual safety attestation in the HR portal. Temporary domestic work from a location outside the home office state may require payroll location review if extended beyond 30 days. Use of personal devices f', 'ffs. Managers may define team-specific overlap hours when projects involve coordination across offices in different time zones. Home-office expenses are reimbursable only for pre-approved categories listed in the internal procurement guide. Employees should re', 'Working from another country is capped at 14 days in a rolling 12-month period without permit support. Beyond 14 days, employees must open a Global Mobility case and obtain HR, Legal, and Payroll approval. Violations can trigger immigration, payroll, and tax e', 'Employees handling customer data while traveling must use VPN, hardware-backed MFA, and encrypted storage. Lost or stolen devices must be reported within one hour to security operations. Use of public charging stations is discouraged unless a data-blocking ada']\n",
      "\n",
      "Query: Can I work remotely from cafes and home?\n",
      "1. DOC-HB-REMOTEWORK-FIX-00 | score=0.1312 | Z-Tech encourages remote work from home, co-working spaces, or temporary domestic locations. Employe\n",
      "2. DOC-HB-REMOTEWORK-FIX-03 | score=-0.1121 | view ergonomic setup guidance quarterly and complete the annual safety attestation in the HR portal.\n",
      "3. DOC-HB-REMOTEWORK-FIX-02 | score=-0.1139 | ffs. Managers may define team-specific overlap hours when projects involve coordination across offic\n",
      "4. DOC-HB-INTERNATIONALWORK-FIX-00 | score=-0.2463 | Working from another country is capped at 14 days in a rolling 12-month period without permit suppor\n",
      "5. DOC-HB-SECURITY-FIX-00 | score=-0.2610 | Employees handling customer data while traveling must use VPN, hardware-backed MFA, and encrypted st\n",
      "\n",
      "Answer: Yes, you can work remotely from home and cafes or co-working spaces, but you must stay reachable during assigned hours, use approved devices, and enable corporate VPN on public Wi-Fi. Temporary domestic remote work outside your home office state is allowed but may require payroll review if over 30 days [Chunk 1].\n"
     ]
    }
   ],
   "source": [
    "# 8) Assemble End-to-End RAG Pipeline + 9/10 Smoke Tests and Evaluation\n",
    "\n",
    "from rag_tutorials.evaluation import evaluate_single, summarize\n",
    "\n",
    "sample_queries = queries[: cfg.sample_eval_size]\n",
    "rows = [\n",
    "    evaluate_single(\n",
    "        query=q,\n",
    "        retrieval_fn=lambda question: retrieve_dense(question, top_k=cfg.top_k),\n",
    "        answer_fn=lambda question, context: answer_with_context(question, context, model=cfg.chat_model),\n",
    "        top_k=cfg.top_k,\n",
    "    )\n",
    "    for q in sample_queries\n",
    "]\n",
    "\n",
    "metrics = summarize(rows)\n",
    "print(\"Tutorial 1 metrics:\", metrics)\n",
    "\n",
    "# Show one trace row for novice debugging\n",
    "trace = sample_queries[0]\n",
    "trace_answer, trace_retrieved = rag_answer(trace.question, top_k=cfg.top_k)\n",
    "print(\"\\nQuery:\", trace.question)\n",
    "for idx, row in enumerate(trace_retrieved, start=1):\n",
    "    print(f\"{idx}. {row.chunk_id} | score={row.score:.4f} | {row.text[:100]}\")\n",
    "print(\"\\nAnswer:\", trace_answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}